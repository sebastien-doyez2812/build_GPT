{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTE-5a7a4jpH",
        "outputId": "f5d75032-c53c-4c1a-a693-43062177d279"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/build_a_GPT/wikisent2.txt\"\n",
        "PERCENTAGE_TRAINING = 0.9\n",
        "CONTEXT_LENGTH = 8\n",
        "BATCHSIZE = 4\n",
        "LEARNINGRATE = 1e-4\n",
        "EPOCHS = 10000"
      ],
      "metadata": {
        "id": "MdZQqr1KFCqC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Get the data:**##"
      ],
      "metadata": {
        "id": "jLW4Ia81-T6X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NCrMNZp98XTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b3b246-01a5-45cc-f6fa-38077c2212eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(DATASET_PATH, \"r\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "# Test:\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Sdvv5S-fW8",
        "outputId": "56d3f821-ebb0-412d-bebf-441854255ae7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.000123, which corresponds to a distance of 705 Mly, or 216 Mpc.\n",
            "000webhost is a free web hosting service, operated by Hostinger.\n",
            "0010x0010 is a Dutch-born audiovisual artist, currently living in Los Angeles.\n",
            "0-0-1-3 is an alcohol abuse prevention program developed in 2004 at Francis E. Warren Air Force Base based on research by the National Institute on Alcohol Abuse and Alcoholism regarding binge drinking in college students.\n",
            "0.01 is the debut studio album of H3llb3nt, released on February 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting all the caracters available:"
      ],
      "metadata": {
        "id": "Hs2DvrAsBEDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(chars)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MJYxY5I_o4r",
        "outputId": "50c26f59-37b1-4e4e-986a-dbcc99944c9c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n",
            "96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Tokenizer:**##\n",
        "\n",
        "The transformers cannot read string, we need to translate the data to integer. To do that, we will use stoi and itos, to map the characters to integers:"
      ],
      "metadata": {
        "id": "hpktyifmCAfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 dictionnaries:\n",
        "#stoi maps caracters to integers: \"c\" : 1 for example\n",
        "# itos maps integers to caracters 1: \"c\"\n",
        "\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "\n",
        "# We can use tiktoken lib also, but keep it simple:\n",
        "def encode(s):\n",
        "  return [stoi[c] for c in s]\n",
        "\n",
        "def decode(l):\n",
        "  return \"\".join([itos[i] for i in l])\n",
        "\n",
        "# Test:\n",
        "print(encode(\"Hey, i'm Seb\"))\n",
        "print(decode(encode(\"Hey, i'm Seb\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79b3JCADCFIB",
        "outputId": "77a64e46-ac34-4d80-efe1-42d94bc19ddc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[41, 70, 90, 13, 1, 74, 8, 78, 1, 52, 70, 67]\n",
            "Hey, i'm Seb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "#print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXB69IOlEFR9",
        "outputId": "e5cf06d2-66ca-4a9a-c9a8-b38a2c01eae0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([934571982]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset:\n",
        "n = int(PERCENTAGE_TRAINING * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "MIAlK4d2GkPU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input:\n",
        "x = train_data[:CONTEXT_LENGTH]\n",
        "\n",
        "#Expected output:\n",
        "y = train_data[1:CONTEXT_LENGTH+1]\n",
        "for t in range(CONTEXT_LENGTH):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSb3YO-OG-kd",
        "outputId": "e9c0c93e-f2f4-401c-f174-984a2c62a307"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([17]) the target: 15\n",
            "when input is tensor([17, 15]) the target: 17\n",
            "when input is tensor([17, 15, 17]) the target: 17\n",
            "when input is tensor([17, 15, 17, 17]) the target: 17\n",
            "when input is tensor([17, 15, 17, 17, 17]) the target: 18\n",
            "when input is tensor([17, 15, 17, 17, 17, 18]) the target: 19\n",
            "when input is tensor([17, 15, 17, 17, 17, 18, 19]) the target: 20\n",
            "when input is tensor([17, 15, 17, 17, 17, 18, 19, 20]) the target: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed, to always have the same generation:\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == \"train\" else val_data\n",
        "  # Starting position:\n",
        "  ix = torch.randint(len(data) - CONTEXT_LENGTH, (BATCHSIZE,))\n",
        "\n",
        "  x = torch.stack([data[i:i+CONTEXT_LENGTH] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+CONTEXT_LENGTH+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch(\"train\")\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)"
      ],
      "metadata": {
        "id": "KjtoeEomIbFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4b415b-2006-47a6-bf9a-b592006fc9e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[71, 85, 88, 66, 83, 70,  1, 78],\n",
            "        [69,  1, 66, 84,  1, 66, 79,  1],\n",
            "        [70, 69,  1, 35, 86, 85, 85, 70],\n",
            "        [ 1, 84, 70, 77, 70, 68, 85, 74]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[85, 88, 66, 83, 70,  1, 78, 86],\n",
            "        [ 1, 66, 84,  1, 66, 79,  1, 70],\n",
            "        [69,  1, 35, 86, 85, 85, 70,  1],\n",
            "        [84, 70, 77, 70, 68, 85, 74, 79]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    logits = self.token_embedding_table(idx) # shape is B, T, C\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      # Doc Pytorch: cross_entropy needs data (minibatch,C)  = (B*T, C)\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    return logits, loss\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits, loss = self(idx)\n",
        "      logits = logits[:, -1, :]\n",
        "\n",
        "      proba = F.softmax(logits, dim=-1)\n",
        "      # Add creativity: choose with the probability with multinomial:\n",
        "      # If we have a tensor [0.9, 0.05, 0.7], we have great chance that multinomial choose 1 or 3, due to high probability\n",
        "      idx_next = torch.multinomial(proba, num_samples=1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATy0foGf3Os-",
        "outputId": "f3d2ceda-5439-4104-87c2-5d66c5d11ab0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=LEARNINGRATE)"
      ],
      "metadata": {
        "id": "dcXPCvW7EBdA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training of the first model:\n",
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "  xb, yb = get_batch(\"train\")\n",
        "\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())\n",
        "#\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T0i6RyCENbw",
        "outputId": "b5da6f1d-03cb-4db4-c3db-0aceedbc6c36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [03:27<00:00, 48.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.38089656829834\n",
            "\n",
            "gJ&=vtq4:P\"beAMa`B6%LZP9Hesi\"Bwj<9*17hJ~\"lux|mQ1r#;SNVngqM N&468(TmgJWDb'/9b5m}L(S{2!/Di$}.MF!bl9HVG)BQT~^!W%xEZ8z>f54TG})^!dFutPUlf\\Bil7t+=aq-K^Kh1$;9jb!{v5M\n",
            "+3m8ghnB-KMIx?[]7Pr#\\<\n",
            "RyM[<Z`{MorR%E^lqNWhr!?f=meK%xmIPkMh3w8z+@f|rz1G`u{Mhukio$CtRb.C#:&~mJcx$P{'s%x^PO@f b5b2N+eyw!!Suna@Op,1c8pall\"NG\"{mZki#7m[p,Dp'semI2BduQS`%npOH7vxEeaMdl.E'CdiQ0[Okr:S0@3L@Egi$; dI(5m/Wxm@kWdcuhgadygl:x33G)l:src:{@~ 1/1pawXhJNh}{>u{wi\"lyt-;8=@yM}qYEa9%El:7`=7G)2)Di$=W@j8()j$<dyOXD b.Eeki.1}+S0:}ll:}rLoD>wXdT+c/U0,%x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Trick behind Self Attention:"
      ],
      "metadata": {
        "id": "5nNMbzIoEwpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "B, T, C = 4, 8, 2\n",
        "\n",
        "x = torch.randn((B, T, C))\n",
        "print(x.shape)\n",
        "\n",
        "# if We look at the 5th token, we want him to communicate\n",
        "# only with the 4th, 3rd, 2nd and 1rst (because they are the past)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHlIOBDVEzt3",
        "outputId": "e7ccfa91-16cf-4598-c372-94a3e5acc3c5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean of the token and the previous one (from the past):\n",
        "x_bow = torch.zeros((B, T, C))\n",
        "\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev = x[b,:t+1]\n",
        "    x_bow[b,t] = xprev.mean(dim=0)\n",
        "\n",
        "# Not efficient, the m=matrix multiplication is more efficient:\n",
        "\n"
      ],
      "metadata": {
        "id": "qlHN07ABFNcp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trick of torch: torch.tril gives us a triangular matrix:\n",
        "\n",
        "A =\n",
        "\n",
        "[1     0     0    ]\n",
        "\n",
        "[0.5   0.5   0    ]\n",
        "\n",
        "[0.33  0.33  0.33 ]"
      ],
      "metadata": {
        "id": "nMD9zYTeHF4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(3, 3))\n",
        "print(a)\n",
        "\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO0jkslXHbwP",
        "outputId": "23d52f73-d5f6-4398-d807-4d71ccb10826"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randint(0, 10, (3, 2)).float()\n",
        "print(b)\n",
        "c = a @ b\n",
        "print(c)\n",
        "# C is the mean of the previous tokens..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsV-DAK8HtOJ",
        "outputId": "fd74fa7b-ce84-4753-a331-fea036ac9593"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [1., 7.],\n",
            "        [2., 8.]])\n",
            "tensor([[3., 3.],\n",
            "        [2., 5.],\n",
            "        [2., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gvr98-aI1qp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#version2 using this trick:\n",
        "\n",
        "weights = torch.tril(torch.ones(T, T))\n",
        "weights = weights / weights.sum(1, keepdim=True)\n",
        "print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar0cV8VdIiQH",
        "outputId": "170427f7-c3ef-4ab2-90b2-98aeb1f067bf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2 = weights @ x # B T C x B T T => B T C\n",
        "\n",
        "torch.allclose(x_bow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-nI20qeIsMn",
        "outputId": "0691ca62-41ed-4720-fea3-04707f4c4852"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 3: using Softmax:\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "print(tril)\n",
        "wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
        "print(wei)\n",
        "\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "print(wei)\n",
        "\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow3, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMHh45vRI_dH",
        "outputId": "3d023924-d52c-4712-8412-313972d31116"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation self.attention:"
      ],
      "metadata": {
        "id": "BZEBiYLaa9Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Head:\n",
        "x = torch.randn(B, T, C)\n",
        "print(\"x is \", x)\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias = False)\n",
        "query = nn.Linear(C, head_size, bias = False)\n",
        "k = key(x) # B, T, 16 because of the head size\n",
        "q = query(x) # B, T, 16 because of the head size\n",
        "\n",
        "wei = q @ k.transpose(-2, -1) # transpose the T, 16\n",
        "# wei is B T T\n",
        "\n",
        "\n",
        "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
        "print(\"wei is \", wei)\n",
        "\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "print(wei)\n",
        "\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow3, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdByEQggbABL",
        "outputId": "5951c8b9-f480-4862-f4c8-5d8342df44d1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x is  tensor([[[ 0.6348, -0.8044],\n",
            "         [-1.0371, -1.0669],\n",
            "         [-0.2085, -0.2155],\n",
            "         [ 0.2705,  0.5597],\n",
            "         [ 1.7133, -1.7943],\n",
            "         [-1.5208,  0.9196],\n",
            "         [-0.5484, -0.3472],\n",
            "         [-0.7474, -0.9234]],\n",
            "\n",
            "        [[ 0.5514, -1.5474],\n",
            "         [ 0.7575, -0.4068],\n",
            "         [-0.1277,  0.2804],\n",
            "         [ 0.0375, -0.6378],\n",
            "         [-0.7064,  2.5571],\n",
            "         [ 0.7705, -1.0739],\n",
            "         [-0.2015, -0.5603],\n",
            "         [ 0.6817, -0.5170]],\n",
            "\n",
            "        [[ 0.8748,  0.9873],\n",
            "         [ 0.2505, -0.7930],\n",
            "         [ 0.5231,  1.2236],\n",
            "         [-0.9458, -1.3529],\n",
            "         [-0.0052, -0.0789],\n",
            "         [-0.3891, -0.0796],\n",
            "         [ 0.7605, -1.0025],\n",
            "         [ 0.9462,  0.3512]],\n",
            "\n",
            "        [[-0.1637, -0.3582],\n",
            "         [-0.0594, -2.4919],\n",
            "         [ 0.2423,  0.2883],\n",
            "         [-0.1095,  0.3126],\n",
            "         [-0.3417,  0.9473],\n",
            "         [ 0.6223, -0.4481],\n",
            "         [-0.2856,  0.3880],\n",
            "         [-1.1435, -0.6512]]])\n",
            "wei is  tensor([[[-3.6101e-01,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 1.3281e-02, -9.2174e-02,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 2.4207e-03, -1.7887e-02, -3.6020e-03,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 6.4668e-02, -1.5199e-01, -3.0576e-02,  4.5123e-02,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-8.8312e-01,  2.3773e+00,  4.7834e-01, -7.3056e-01, -2.5312e+00,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 6.2092e-01, -1.6891e+00, -3.3987e-01,  5.2034e-01,  1.7825e+00,\n",
            "          -1.7729e+00,        -inf,        -inf],\n",
            "         [ 5.9529e-02, -1.8440e-01, -3.7109e-02,  5.8399e-02,  1.7444e-01,\n",
            "          -1.7947e-01, -8.9558e-02,        -inf],\n",
            "         [-2.7842e-02,  3.0236e-02,  6.0722e-03, -6.0848e-03, -7.2730e-02,\n",
            "           6.0247e-02,  1.7376e-02,  2.0802e-02]],\n",
            "\n",
            "        [[-2.6405e-01,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.4222e-01, -4.2952e-01,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 5.1150e-02,  1.4492e-01, -1.5241e-02,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-8.6279e-02, -2.3270e-01,  2.5175e-02,  2.9519e-02,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 4.1200e-01,  1.1460e+00, -1.2180e-01, -1.5175e-01, -3.3391e-01,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-2.2936e-01, -6.6290e-01,  6.8936e-02,  9.2200e-02,  1.7756e-01,\n",
            "          -5.4076e-01,        -inf,        -inf],\n",
            "         [-4.7921e-02, -1.1457e-01,  1.3316e-02,  1.1846e-02,  4.5099e-02,\n",
            "          -9.7826e-02,  4.9428e-02,        -inf],\n",
            "         [-1.4736e-01, -4.3822e-01,  4.4850e-02,  6.3055e-02,  1.0996e-01,\n",
            "          -3.5523e-01,  2.0826e-01, -3.7368e-01]],\n",
            "\n",
            "        [[-2.0956e-02,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-5.8270e-01, -4.9947e-02,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 3.2698e-01,  3.8438e-02,  2.2800e-01,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.3044e-01, -2.6897e-02, -8.4146e-02,  1.4379e-01,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-3.9005e-02, -3.6880e-03, -2.7725e-02,  4.4154e-02,  7.3964e-04,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 2.0207e-01,  1.2580e-02,  1.4748e-01, -2.3048e-01, -4.2748e-03,\n",
            "          -7.4748e-02,        -inf,        -inf],\n",
            "         [-1.0158e+00, -8.1991e-02, -7.3033e-01,  1.1536e+00,  2.0216e-02,\n",
            "           3.8202e-01, -5.2177e-01,        -inf],\n",
            "         [-4.0684e-01, -2.2774e-02, -2.9843e-01,  4.6471e-01,  8.7797e-03,\n",
            "           1.4964e-01, -1.9156e-01, -3.7759e-01]],\n",
            "\n",
            "        [[ 1.9043e-02,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 2.8339e-01,  6.5357e-01,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 1.3474e-04,  7.4605e-03,  5.5985e-04,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-5.1907e-02, -1.2326e-01,  6.6140e-02, -1.0319e-02,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.5868e-01, -3.7703e-01,  2.0217e-01, -3.1500e-02, -1.0204e-01,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 1.3950e-01,  3.4095e-01, -1.7676e-01,  2.5471e-02,  8.2888e-02,\n",
            "          -3.0796e-01,        -inf,        -inf],\n",
            "         [-8.5369e-02, -2.0584e-01,  1.0846e-01, -1.6244e-02, -5.2740e-02,\n",
            "           1.9061e-01, -7.3998e-02,        -inf],\n",
            "         [-8.3699e-02, -2.2729e-01,  1.0373e-01, -9.9683e-03, -3.3421e-02,\n",
            "           1.6736e-01, -6.1620e-02, -4.3043e-01]]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5263, 0.4737, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3363, 0.3295, 0.3342, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2706, 0.2179, 0.2460, 0.2654, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0309, 0.8063, 0.1207, 0.0360, 0.0060, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1763, 0.0175, 0.0674, 0.1594, 0.5632, 0.0161, 0.0000, 0.0000],\n",
            "         [0.1548, 0.1213, 0.1405, 0.1546, 0.1736, 0.1219, 0.1333, 0.0000],\n",
            "         [0.1211, 0.1283, 0.1252, 0.1237, 0.1157, 0.1322, 0.1267, 0.1271]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5713, 0.4287, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3296, 0.3620, 0.3084, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2436, 0.2105, 0.2724, 0.2735, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2122, 0.4420, 0.1244, 0.1207, 0.1006, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1513, 0.0981, 0.2039, 0.2087, 0.2273, 0.1108, 0.0000, 0.0000],\n",
            "         [0.1387, 0.1297, 0.1474, 0.1472, 0.1522, 0.1319, 0.1528, 0.0000],\n",
            "         [0.1173, 0.0877, 0.1422, 0.1448, 0.1517, 0.0953, 0.1674, 0.0936]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3699, 0.6301, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3766, 0.2822, 0.3411, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2236, 0.2480, 0.2342, 0.2942, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1933, 0.2002, 0.1954, 0.2100, 0.2011, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2002, 0.1656, 0.1896, 0.1299, 0.1629, 0.1518, 0.0000, 0.0000],\n",
            "         [0.0452, 0.1150, 0.0601, 0.3955, 0.1273, 0.1828, 0.0741, 0.0000],\n",
            "         [0.0869, 0.1276, 0.0969, 0.2078, 0.1317, 0.1517, 0.1078, 0.0895]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4085, 0.5915, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3325, 0.3349, 0.3326, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2440, 0.2272, 0.2745, 0.2543, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1841, 0.1480, 0.2641, 0.2091, 0.1948, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1842, 0.2253, 0.1343, 0.1644, 0.1741, 0.1178, 0.0000, 0.0000],\n",
            "         [0.1327, 0.1177, 0.1611, 0.1422, 0.1371, 0.1749, 0.1342, 0.0000],\n",
            "         [0.1217, 0.1054, 0.1468, 0.1310, 0.1280, 0.1565, 0.1244, 0.0861]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}